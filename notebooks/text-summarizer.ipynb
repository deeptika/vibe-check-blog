{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461f24b8-50a6-4e92-9ee8-a1edcebdf044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate_number</th>\n",
       "      <th>content_type</th>\n",
       "      <th>network</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>CBS</td>\n",
       "      <td>@Deano-n4w</td>\n",
       "      <td>Donald Trump's reasoning is lost üò¢</td>\n",
       "      <td>2024-08-27T09:51:01Z</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>CBS</td>\n",
       "      <td>@noobpeepxpostyguitarists5381</td>\n",
       "      <td>2:05:31 this aged well</td>\n",
       "      <td>2024-08-26T09:48:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>CBS</td>\n",
       "      <td>@noobpeepxpostyguitarists5381</td>\n",
       "      <td>The only facts is that words shouldn't be impo...</td>\n",
       "      <td>2024-08-26T09:44:19Z</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>CBS</td>\n",
       "      <td>@sandhyagudigudi3998</td>\n",
       "      <td>Biden sir GodenBird flying ‚ù§Trumpsir like Baby...</td>\n",
       "      <td>2024-08-22T02:10:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>CBS</td>\n",
       "      <td>@cherylcallahan5402</td>\n",
       "      <td>LIONEL NATION AND THE MATE ARE THE BEST BEST</td>\n",
       "      <td>2024-08-21T17:11:52Z</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debate_number content_type network                         author  \\\n",
       "0              1      comment     CBS                     @Deano-n4w   \n",
       "1              1      comment     CBS  @noobpeepxpostyguitarists5381   \n",
       "2              1      comment     CBS  @noobpeepxpostyguitarists5381   \n",
       "3              1      comment     CBS           @sandhyagudigudi3998   \n",
       "4              1      comment     CBS            @cherylcallahan5402   \n",
       "\n",
       "                                                text          published_at  \\\n",
       "0                 Donald Trump's reasoning is lost üò¢  2024-08-27T09:51:01Z   \n",
       "1                             2:05:31 this aged well  2024-08-26T09:48:00Z   \n",
       "2  The only facts is that words shouldn't be impo...  2024-08-26T09:44:19Z   \n",
       "3  Biden sir GodenBird flying ‚ù§Trumpsir like Baby...  2024-08-22T02:10:30Z   \n",
       "4       LIONEL NATION AND THE MATE ARE THE BEST BEST  2024-08-21T17:11:52Z   \n",
       "\n",
       "   like_count  public  \n",
       "0           0    True  \n",
       "1           0    True  \n",
       "2           1    True  \n",
       "3           0    True  \n",
       "4           1    True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/dataset_merged.csv', lineterminator='\\n')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f84ca1f-176b-484a-8fa7-fab4f8a6f356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195324 entries, 0 to 195323\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   debate_number  195324 non-null  int64 \n",
      " 1   content_type   195324 non-null  object\n",
      " 2   network        195324 non-null  object\n",
      " 3   author         195324 non-null  object\n",
      " 4   text           195324 non-null  object\n",
      " 5   published_at   195324 non-null  object\n",
      " 6   like_count     195324 non-null  int64 \n",
      " 7   public         195324 non-null  bool  \n",
      "dtypes: bool(1), int64(2), object(5)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5292a5cf-7f4f-4518-a7e3-8f401028fca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/deeptikakannan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/deeptikakannan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of all comments:\n",
      "Trump 2024! Trump 2020! Trump 2020!!! Trump. Trump 2020.\n",
      "\n",
      "Summary for 2020 Presidential Debate - Biden vs Trump:\n",
      "Trump 2020! Trump 2020!!! Trump 2020.\n",
      "\n",
      "Summary for 2024 Presidential Debate 1 - Biden vs Trump:\n",
      "Trump 2024! Trump is by far the BEST president of the USA, period. Trump 2024.\n",
      "\n",
      "Summary for 2024 Presidential Debate 2 - Harris vs Trump:\n",
      "üòÇ Trump trump trump trump trump trump trump trump trump trump trump Trump won Where my Russian bot homies at I trust none of them both. Trump trump trump trump trump trump trump trump trump!!!!! Trump 2024!\n",
      "\n",
      "Summary for 2024 Vice Presidential Debate - Vance vs Walz:\n",
      "JD Vance won very intelligent and calm Vance clearly dominated the debate Vance WON‚ù§‚ù§‚ù§ Vance actually thinks Chump won in 2020 Vance won but loved this debate! Vance destroyed Walz JD Vance won Harris2024 Vance won Vance gave me a chubby and I'm not even like that. JD Vance ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§ Vance JD Vance answer all questions with confidence Vance!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import Counter\n",
    "import heapq\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def summarize_text(text, num_sentences=3):\n",
    "    # tokenize and remove stop words\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    word_tokens = [word for word in word_tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # calculate word frequencies\n",
    "    word_freq = Counter(word_tokens)\n",
    "    \n",
    "    # calculate sentence scores based on word frequencies\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in word_freq:\n",
    "                if len(sentence.split()) < 30:  # Ignore long sentences\n",
    "                    if sentence not in sentence_scores:\n",
    "                        sentence_scores[sentence] = word_freq[word]\n",
    "                    else:\n",
    "                        sentence_scores[sentence] += word_freq[word]\n",
    "    \n",
    "    # top n sentences with highest scores\n",
    "    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    \n",
    "    # join summary\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "all_comments = ' '.join(df['text'].dropna().astype(str))\n",
    "summary = summarize_text(all_comments, num_sentences=5)\n",
    "print(\"Summary of all comments:\")\n",
    "print(summary)\n",
    "\n",
    "debates = ['2020 Presidential Debate - Biden vs Trump',\n",
    "           '2024 Presidential Debate 1 - Biden vs Trump',\n",
    "           '2024 Presidential Debate 2 - Harris vs Trump',\n",
    "           '2024 Vice Presidential Debate - Vance vs Walz']\n",
    "\n",
    "i = 0\n",
    "\n",
    "# summarizing comments for each debate separately\n",
    "for debate_num in df['debate_number'].unique():\n",
    "    debate_comments = ' '.join(df[df['debate_number'] == debate_num]['text'].dropna().astype(str))\n",
    "    debate_summary = summarize_text(debate_comments, num_sentences=3)\n",
    "    print(f\"\\nSummary for {debates[i]}:\")\n",
    "    i += 1\n",
    "    print(debate_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
